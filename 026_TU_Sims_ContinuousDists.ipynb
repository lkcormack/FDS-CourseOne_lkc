{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Simulation involving Continuous Random Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Objectives:\n",
    "The objectives of this exercise are to further expand on our skills of simulating data corresponding to real-world experimental situations. The second is to better understand continuous random variables and their probability density functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Goals:\n",
    "\n",
    "* Understanding the difference between discrete and continuous random processes\n",
    "* Ditto for discrete probability distribution and continuous probability density functions\n",
    "* Simulating continuous random processes\n",
    "* Computing probabilities from probability density functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From Discrete to Continuous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last time, we explored *discrete* random variables – variables that can only take on a certain finite number of values. This occurs when, for example, we are *counting* things, because counts can only be integers, and nobody actually counts anything to infinity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A discrete example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes we might measure something and put it into a category based on the measurement. For example, people who fish must measure each fish they catch and determine if it is \"too small\" or \"not too small\"; if it's \"not too small\", then they get to keep it, if it is too small, then they must release it. That's a discrete (binomial) variable. In fact, if we knew the distribution of fish sizes in the water, we could easily predict how often we would get a fish we could keep."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Somebody who's really into fishing might make up more categories, like \"minnow\", \"little\", \"okay\", \"big\", and \"monster\". Over time, the fisherperson would get a general idea in their head of how often each type of fish was caught. Or they might even keep a tally in a notebook of how much of each size of fish was caught. Let's say they kept a tally and, after they had caught a total of 10,000 fish over the years, the distribution of fish sizes looked like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As always, let's import our libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as rnd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now do the fishing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rnd.seed(42) # Set the seed\n",
    "\n",
    "n = 10000 # Set the number of samples – a lot of fishing!!\n",
    "\n",
    "size_categories = ['minnow', 'little', 'okay', 'big', 'monster']  # fish categories\n",
    "size_probabilities = [0.05, 0.1, 0.5, 0.25, 0.1]                  # fish probabilities\n",
    "counts = np.zeros(len(size_categories))                           # array to hold the counts\n",
    "\n",
    "sizes = rnd.choice(size_categories, size=n, p=size_probabilities) # go fishing!\n",
    "\n",
    "for i in size_categories :\n",
    "    counts[size_categories.index(i)] = np.sum(sizes == i)         # count the fish\n",
    "\n",
    "fish_probabilities = counts/n                                     # calculate the probabilities\n",
    "\n",
    "\n",
    "plt.bar(size_categories, fish_probabilities)                      # Plot the histogram\n",
    "plt.xlabel('Fish Size')\n",
    "plt.ylabel('Probability of Catching')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a ***discrete probability distribution***. What that means is we can look at any one category, like \"big\", and see that there is about a – what? – 24% chance of catching a \"big\" fish. If these categories cover all sizes of fish, then the probability of catching *any* of these fish should sum to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The sum of the probabilities is {np.sum(probs):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A continuous example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While our fisherperson above formed discrete categories for the size of fish, a wildlife biologist or a state game warden would actually *measure* the fish. The length of the fish is ***continuous*** variable. One way to think of a continuous variable is a variable that, when given two values, you can always come up with the third value between them. So if one fish was 45.005 cm long, and another was 45.006 cm long, then it's possible to have a fish that is 45.0055 cm long. And you can pay this out to as many decimal places you wish. With a discreet variable, this is not true; there is nothing between \"big\" and \"monster\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: Some variables, like counts, are inherently discrete (like when we count different kinds of things). Other variables, like fish length, can be categorized into a discrete variable, like our fisherperson did above, even though they are ultimately continuous. Whether to treat a continuous variable as discrete is sometimes a good idea, sometimes not. It's very situation dependent.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Here's a distribution of fish lengths (in cm) that might be measured by a biologist:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate a continuous random variable \n",
    "n_measurements = 1000 \n",
    "ave_fish_length = 40\n",
    "std_fish_length = 10\n",
    "\n",
    "fish_lengths = rnd.normal(ave_fish_length, std_fish_length, size=n_measurements)\n",
    "\n",
    "# Plot the results in a histogram\n",
    "plt.hist(fish_lengths, bins=20, density=True, \n",
    "         color='g', alpha=0.75, edgecolor='k')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Fish Lengths')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This histogram looks like a finer-grained version of our fisherperson's. In some sense it is, but in some sense it isn't. Notice the values on the y-axis. Does it looks like they sum to 1? If we take the highest value, which looks like it's maybe 0.042, and mutiply it by the number bins (20), what would we get?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do that multiplication in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "20 * 0.042"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, no, and since most of the y-axis values are much smaller, these y values definitely do not sum to anything close to 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's actually do the sum. To do this, we'll use the `np.histogram()` function with the exact same arguments that we used to plot the histogram, and this will give us the y-axis values that we can sum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fish_densities, fish_bins = np.histogram(fish_lengths, bins=20, density=True)\n",
    "density_sum = np.sum(fish_densities)\n",
    "print(f\"The sum of the densities is {density_sum:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, again, nowhere near 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what are these y-values? They are ***probability densities***. To get actual probabilities, we have to ***integrate*** the probability density function.\n",
    "\n",
    "The reason comes down to this: with a continuous variable, the probability of any one ***exact*** number occurring to an infinite number of decimal places is, in the limit, 0. So, for example, what are the chances of catching a fish that is exactly 41.967363647t8909483798365836256263748 cm long? Very very very small – in the limit (imagine adding thousands of more decimal places), 0. \n",
    "\n",
    "But what ***can*** do, thanks to calculus, is compute the probability of catching a fish over some *interval* of lengths. In other words we can compute, for example, the probability of catching a fish\n",
    "\n",
    "* bigger than 40cm.\n",
    "* smaller than 25cm.\n",
    "* between 30 and 50cm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do a quick thought experiment in your head: given the distribution of fish lengths above, what would be the probability of catching a fish that was somewhere between 0 and 100 cm in length?\n",
    "\n",
    "It would have to be 1.0, right? So ***something*** has to sum to 1.0! But what?\n",
    "\n",
    "What sums to 1 is the ***area*** (or \"probability mass\") of the distribution. Recall that the integral of a function is\n",
    "$$\n",
    "\\int_{}{} {f(x)\\delta x}\n",
    "$$\n",
    "Well, in this case, $f(x)$ is the sequence of the heights of the bars – the probability densities – and the $\\delta x$ values are just the bin widths. So we can compute area of our distribution by summing the product of the heights and widths of the bars:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_sum = np.sum(fish_densities * np.diff(fish_bins))\n",
    "print(f\"The area of the distribution is {probs_sum:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Voila!!!*** So to compute probabilities of things for ***continuous*** variables, we need know the probability density function, or have an emperical estimate of it, and then compute ***areas under the function***, because it's the areas under the function that correspond to the probabilities of things happening."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing Probabilities \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a few different ways we can go about estimating probabilities of things when we have a set of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computing Probabilities by Counting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conceptually, the easiest way to estimate a probability is to count the number of observations in the interval of interest, and then divide by the total number of observations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, for example, given the above fish data, what's the probability of catching a fish bigger than 40 cm? To do that, will just some up the number of fish more than 40 cm long, and divide it by the total number of fish:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fish_over = np.sum(fish_lengths > 40)\n",
    "p_fish_over = fish_over / n_measurements\n",
    "print(f\"The probability of catching a fish over 40 cm is {p_fish_over:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's make a plot to illustrate that probability. First, we'll use `np.histogram()` to get the relevant stuff for plotting. (We're not going to use `plt.hist()` to plot, we're going to use `plt.bar` with the data from `np.histogram()` because that will make it easier for us to overlay plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the histogram bins and counts\n",
    "counts, bins = np.histogram(fish_lengths, bins=20) # Get the histogram bin edges and counts\n",
    "bin_width = bins[1] - bins[0]                      # Get the bin width\n",
    "bin_centers = bins[:-1] + bin_width/2              # Get the bin centers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's make a plot showing the probability of getting a fish more than 40 cm long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set the threshold\n",
    "threshold = 40\n",
    "\n",
    "# Plot the histogram with different colors for bars above and below the threshold\n",
    "plt.bar(bin_centers, counts, \n",
    "        width=bin_width, color='b', edgecolor='k')\n",
    "plt.bar(bin_centers[bin_centers > threshold], counts[bin_centers > threshold], \n",
    "        width=bin_width, color='r', edgecolor='k', alpha=0.5)\n",
    "\n",
    "# Add a vertical line for the threshold\n",
    "plt.axvline(x=threshold, color='k', linestyle='--')\n",
    "\n",
    "plt.xlabel('Fish Length')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Fish Length Histogram')\n",
    "plt.text(50, 100, f'P(X > {threshold}) = {p_fish_over:.2f}')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting those bin centers and widths along with the counts was so darn useful, we should make it a function! Do so in the code cell below; the function should take the data and the number of bins as input, and return the counts, bin centers, and bin widths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist_data(data, n_bins) :\n",
    "    \"\"\"\n",
    "    Computes the histogram counts, bin centers, and bin_widths\n",
    "    from the data and number of bins\n",
    "    \"\"\"\n",
    "    # your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now test your function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c, bc, bw = hist_data(fish_lengths, 20)\n",
    "print(f\"The bin centers are {bc}\")\n",
    "print(f\"The bin widths are {bw}\")\n",
    "print(f\"The counts are {c}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, make plots like those above for \n",
    "\n",
    "* fish shorter than 20 cm\n",
    "* fish longer than 60 cm\n",
    "* fish between 30 and 50 cm in length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shorter than 20:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Longer than 60:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Between 30 and 50 cm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computing Probabilities using the Emperical Cumulative Density Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we've learned about 4 powerful Python packages for doing data science. They are:\n",
    "\n",
    "* pandas\n",
    "* seaborn\n",
    "* numpy\n",
    "* matplotlib\n",
    "\n",
    "We are now going to meet a 5th package, `scipy`. For now, we're going to use some of its statistical functions, which are in `scipy.stats`. So let's import that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Money paid for a new car of a certain brand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Parameters for the normal distribution\n",
    "mean_price = 55000\n",
    "std_dev_price = 10000\n",
    "\n",
    "# Generate normally distributed data\n",
    "car_prices = np.random.normal(mean_price, std_dev_price, 1000)\n",
    "\n",
    "# Plot the histogram\n",
    "plt.hist(car_prices, bins=20, density=True, \n",
    "         color='g', alpha=0.75, edgecolor='k')\n",
    "plt.xlabel('Car Price')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Car Price Histogram')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, given these data, let's let `scipy.stats` compute the integral (or cumulative sum) for us. This integral, or cumulative sum of the probabilities of data values is called the ***empirical cumulative distribution function*** (ECDF). We compute it using the `stats.ecdf()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compute ecdf\n",
    "car_ecdf = stats.ecdf(car_prices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `stats.ecdf()` method is pretty cool. you can see what it can do [here](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ecdf.html). We can look at it by plotting its \"quantiles\" (the x axis values corresponding to a given probability) against the probabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(car_ecdf.cdf.quantiles, car_ecdf.cdf.probabilities, marker='.', linestyle='none')\n",
    "plt.xlabel('Car Price')\n",
    "plt.ylabel('ECDF')\n",
    "plt.title('Car Price ECDF')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows, at each point on the x axis, how much of the histogram of is to the right of that point. In other words, what proportion of people were willing to pay up to that price.\n",
    "\n",
    "Does this plot look right? Let's do some reality checks. Looking at the histogram, no cars sold for less than about $25,000. And, sure enough, the ECDF is 0 at $25,000. The most expensive car sold was $90,000 and, sure enough again, the ECDF shows that the probability that people paid less than $90,000 is 1.0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `evaluate()` method to get the area under the histogram of any value we want. So, for example, so see what proportion of people paid less than $50,000 for a car, we just do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_threshold = 50000\n",
    "p_lower = car_ecdf.cdf.evaluate(price_threshold)\n",
    "print(f\"The probability of a car costing less than ${price_threshold} is {p_lower:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to see how many people were willing to pay more than $65,000 for a car, we do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_threshold = 65000\n",
    "p_over = 1 - car_ecdf.cdf.evaluate(price_threshold)\n",
    "print(f\"The probability of somebody paying more than ${price_threshold} is {p_over:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the ECDF method to compute how many people are willing to pay between $40,000 and $60,000 for a car."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now plot a histogram of the car prices with some vertical lines and shading to highlight this price region. Hint: follow the example used in the fish data above (inluding your awesome function to comopute bin centers, etc.) to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computing Probabilities using Theoretical Density Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we've used two methods to calculate probabilities of things:\n",
    "\n",
    "* counting the observations less than some threshold, and dividing by the number of observations\n",
    "* using `scipy.stats.ecdf()` to compute the cumulative sum (discrete integral) of our data, and use that as a look-up-table to get probabilities.\n",
    "\n",
    "However, if we're pretty sure that our data come from a known distribution, such as a Gaussian distribution, we can gain a little more precision by fitting a truly continuous distribution to our data, and using that distribution to compute probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Time spent on a company's website\n",
    "Let's say we are tasked with evaluating how much time people spend on our company's website. Let's say the data we have from 10,000 website visits are these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for the normal distribution\n",
    "rnd.seed(42) # Set the seed so we all get the same results\n",
    "time_mean = 334.6   # mean seconds spent on the website\n",
    "time_std_dev = 31.2 # standard deviation of seconds spent on the website\n",
    "n_visitors = 10000 # number of visitors to the website\n",
    "\n",
    "# Generate random numbers from a normal distribution\n",
    "data = np.random.normal(time_mean, time_std_dev, n_visitors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, plot a histogram of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a histogram of the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could course use one of the above two methods compute probabilities, but the data look pretty \n",
    "Gaussian and, given the complexity of factors that determine exactly how much time spends on a website, a Gaussian isn't a bad bet. So let's fit a continuous Gaussian distribution to the data, and plot it with the histogram to see how well it fits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot the histogram with a normal distribution fit\n",
    "\n",
    "# re-plot the histogram\n",
    "plt.hist(data, bins=30, density=True, alpha=0.6, color='g')\n",
    "\n",
    "# Get the mean and standard deviation of the data\n",
    "data_mean = np.mean(data)\n",
    "data_std_dev = np.std(data)\n",
    "\n",
    "# Calculate the normal distribution \n",
    "xmin, xmax = plt.xlim() # Get the x-axis limits of our histogram\n",
    "x = np.linspace(xmin, xmax, 100) # Make a range of x values for our distribution\n",
    "p = stats.norm.pdf(x, data_mean, data_std_dev) # Normal PDF with the data mean and std dev\n",
    "\n",
    "# Add a line for the normal distribution\n",
    "plt.plot(x, p, 'k', linewidth=2) # Plot the normal distribution line\n",
    "\n",
    "title = f\"Mean = {data_mean:.2f},  Std. Dev. = {data_std_dev:.2f}\"\n",
    "plt.title(title)\n",
    "plt.xlabel('Time Spent on Website (s)')\n",
    "plt.ylabel('Density')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty darn good fit! So, given that we can be comfortable that were dealing with an essentially Gaussian process, we just need to calculate integrals of the Gaussian function to get whatever probabilities we wish. Don't worry about dusting off your high school calculus book! We'll compute them using the `stats.norm.cdf` which gives the cumulative density function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how many people spend fewer that 4 minutes on the site:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute some probabilities using the cdf function\n",
    "time_spent = 256 # time spent on the website in seconds\n",
    "p_less_than = stats.norm.cdf(time_spent, data_mean, data_std_dev)\n",
    "print(f\"The probability of spending less than {time_spent} seconds on the website is {p_less_than:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so that's about 7%. But to better visualize what's going on (and to be able to better impress our boss and co-workers in the future), let's make a figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot histogram of the data original data\n",
    "plt.hist(data, bins=30, density=True, alpha=0.6, color='g')\n",
    "\n",
    "# Compute the normal distribution as before\n",
    "xmin, xmax = plt.xlim()                # Get the histogram limits\n",
    "x = np.linspace(xmin, xmax, 100)       # Create the corresponding range of values\n",
    "p = stats.norm.pdf(x, data_mean, data_std_dev)   # Compute the normal distribution\n",
    "\n",
    "# Plot the normal distribution\n",
    "plt.plot(x, p, 'k', linewidth=2)\n",
    "\n",
    "# Fill the area under the curve less than time_spent\n",
    "x_fill = np.linspace(xmin, time_spent, 100)     # Make the x values for the area less than time spent\n",
    "p_fill = stats.norm.pdf(x_fill, data_mean, data_std_dev)  # Compute the pdf up to time_spent\n",
    "plt.fill_between(x_fill, p_fill, color='r', alpha=0.3) # Fill the area under the curve\n",
    "\n",
    "# Add a vertical line for time_spent\n",
    "plt.axvline(x=time_spent, color='k', linestyle='--')\n",
    "\n",
    "# Add a title and labels\n",
    "plt.title('Time Spent on Website')\n",
    "plt.xlabel('Time Spent (seconds)')\n",
    "plt.ylabel('Density')\n",
    "# Add a text box with the probability\n",
    "plt.text(170, 0.008, f'P(X < {time_spent}) = {p_less_than:.2f}')\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a plot like the above showing how many people spend between 4 and 6 minutes on the website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "Calculating probabilities is fundamental to data science and statistics. In fact, you've probably already done this in early class under the guise of doing \"tests\" and then reporting \"p-values\". Under the hood, those \"tests\" were doing the same things we've been doing the last couple of days.\n",
    "\n",
    "Here, we have dealt with measurements that can be considered as coming from *continuous* probability distributions. To calculate probabilities from continuous distribution, we have three main approaches. These are the:\n",
    "\n",
    "* brute force count & divide method; this mention is assumption free, so it is extremely general\n",
    "* ECDF method; gives the same answers as above, but very useful when comparing distributions (to be covered later)\n",
    "* distribution-fitting method; gives higher precision answers, but requires assuming you know the distribution of the process that created your data (also the way many \"statistical tests\" are done)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
